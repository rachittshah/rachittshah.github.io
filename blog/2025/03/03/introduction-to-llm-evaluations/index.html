<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="AI Engineering, RAG Systems, and Technical Notes"><meta name=author content="Rachitt Shah"><link href=https://rachittshah.github.io/blog/2025/03/03/introduction-to-llm-evaluations/ rel=canonical><link href=../../../../2024/01/01/evaluation-driven-development/ rel=prev><link rel=alternate type=application/rss+xml title="RSS feed" href=../../../../../feed_rss_created.xml><link rel=alternate type=application/rss+xml title="RSS feed of updated content" href=../../../../../feed_rss_updated.xml><link rel=icon href=../../../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.7"><title>Introduction to LLM Evaluations - Rachitt Shah</title><link rel=stylesheet href=../../../../../assets/stylesheets/main.8608ea7d.min.css><link rel=stylesheet href=../../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../../../stylesheets/extra.css><script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-Y379ZJKVSG"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-Y379ZJKVSG",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-Y379ZJKVSG",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta property=og:type content=website><meta property=og:title content="Introduction to LLM Evaluations - Rachitt Shah"><meta property=og:description content="AI Engineering, RAG Systems, and Technical Notes"><meta property=og:image content=https://rachittshah.github.io/assets/images/social/blog/posts/2024-03-03-llm-evaluations.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://rachittshah.github.io/blog/2025/03/03/introduction-to-llm-evaluations/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Introduction to LLM Evaluations - Rachitt Shah"><meta name=twitter:description content="AI Engineering, RAG Systems, and Technical Notes"><meta name=twitter:image content=https://rachittshah.github.io/assets/images/social/blog/posts/2024-03-03-llm-evaluations.png></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#introduction-to-llm-evaluations class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../../../.. title="Rachitt Shah" class="md-header__button md-logo" aria-label="Rachitt Shah" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Rachitt Shah </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Introduction to LLM Evaluations </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/rachittshah/rachittshah.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> rachittshah.github.io </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../../../ class=md-tabs__link> Blog </a> </li> <li class=md-tabs__item> <a href=../../../../../rag/ class=md-tabs__link> RAG Systems </a> </li> <li class=md-tabs__item> <a href=../../../../../ai/ class=md-tabs__link> AI Engineering </a> </li> <li class=md-tabs__item> <a href=../../../../../projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../../../../contact/ class=md-tabs__link> Contact </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation hidden> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../../.. title="Rachitt Shah" class="md-nav__button md-logo" aria-label="Rachitt Shah" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Rachitt Shah </label> <div class=md-nav__source> <a href=https://github.com/rachittshah/rachittshah.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> rachittshah.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../../../../ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../archive/2025/ class=md-nav__link> <span class=md-ellipsis> 2025 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2022/ class=md-nav__link> <span class=md-ellipsis> 2022 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../category/ai/ class=md-nav__link> <span class=md-ellipsis> AI </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/evaluation/ class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/llm/ class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../../rag/ class=md-nav__link> <span class=md-ellipsis> RAG Systems </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../../ai/ class=md-nav__link> <span class=md-ellipsis> AI Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> </a> </li> <li class=md-nav__item> <a href=../../../../../contact/ class=md-nav__link> <span class=md-ellipsis> Contact </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#the-virtuous-cycle-of-llm-development class=md-nav__link> <span class=md-ellipsis> The Virtuous Cycle of LLM Development </span> </a> </li> <li class=md-nav__item> <a href=#why-llm-evaluations-matter class=md-nav__link> <span class=md-ellipsis> Why LLM Evaluations Matter </span> </a> </li> <li class=md-nav__item> <a href=#quantitative-vs-qualitative-evaluations class=md-nav__link> <span class=md-ellipsis> Quantitative vs. Qualitative Evaluations </span> </a> </li> <li class=md-nav__item> <a href=#using-llm-evaluations-in-production class=md-nav__link> <span class=md-ellipsis> Using LLM Evaluations in Production </span> </a> <nav class=md-nav aria-label="Using LLM Evaluations in Production"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#level-1-unit-tests class=md-nav__link> <span class=md-ellipsis> Level 1: Unit Tests </span> </a> <nav class=md-nav aria-label="Level 1: Unit Tests"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pseudo-code-example class=md-nav__link> <span class=md-ellipsis> Pseudo-code Example: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#level-2-model-driven-and-human-evaluations class=md-nav__link> <span class=md-ellipsis> Level 2: Model-Driven and Human Evaluations </span> </a> </li> <li class=md-nav__item> <a href=#level-3-ab-tests-and-user-metrics class=md-nav__link> <span class=md-ellipsis> Level 3: A/B Tests and User Metrics </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#handling-real-world-constraints class=md-nav__link> <span class=md-ellipsis> Handling Real-World Constraints </span> </a> </li> <li class=md-nav__item> <a href=#pitfalls-and-challenges-in-llm-evaluations class=md-nav__link> <span class=md-ellipsis> Pitfalls and Challenges in LLM Evaluations </span> </a> <nav class=md-nav aria-label="Pitfalls and Challenges in LLM Evaluations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#metric-obsession-without-purpose class=md-nav__link> <span class=md-ellipsis> Metric Obsession Without Purpose </span> </a> </li> <li class=md-nav__item> <a href=#ignoring-domain-expertise class=md-nav__link> <span class=md-ellipsis> Ignoring Domain Expertise </span> </a> </li> <li class=md-nav__item> <a href=#no-systematic-evaluation class=md-nav__link> <span class=md-ellipsis> No Systematic Evaluation </span> </a> </li> <li class=md-nav__item> <a href=#overfitting-to-benchmarks class=md-nav__link> <span class=md-ellipsis> Overfitting to Benchmarks </span> </a> </li> <li class=md-nav__item> <a href=#trusting-automated-judges-blindly class=md-nav__link> <span class=md-ellipsis> Trusting Automated Judges Blindly </span> </a> </li> <li class=md-nav__item> <a href=#lack-of-statistical-rigor class=md-nav__link> <span class=md-ellipsis> Lack of Statistical Rigor </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rule-based-workflows-for-llm-evaluations class=md-nav__link> <span class=md-ellipsis> Rule-Based Workflows for LLM Evaluations </span> </a> <nav class=md-nav aria-label="Rule-Based Workflows for LLM Evaluations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-rule-based-evaluations class=md-nav__link> <span class=md-ellipsis> Why Rule-Based Evaluations? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hybrid-evaluation-workflows class=md-nav__link> <span class=md-ellipsis> Hybrid Evaluation Workflows </span> </a> </li> <li class=md-nav__item> <a href=#case-studies-and-industry-learnings class=md-nav__link> <span class=md-ellipsis> Case Studies and Industry Learnings </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content md-content--post" data-md-component=content> <div class="md-sidebar md-sidebar--post" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class="md-sidebar__inner md-post"> <nav class="md-nav md-nav--primary"> <div class=md-post__back> <div class="md-nav__title md-nav__container"> <a href=../../../../ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> <span class=md-ellipsis> Back to index </span> </a> </div> </div> <ul class="md-post__meta md-nav__list"> <li class="md-nav__item md-nav__item--section"> <div class=md-post__title> <span class=md-ellipsis> Metadata </span> </div> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg> <time datetime="2025-03-03 00:00:00+00:00" class=md-ellipsis>2025/03/03</time> </div> </li> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg> <span class=md-ellipsis> in <a href=../../../../category/llm/ >LLM</a>, <a href=../../../../category/evaluation/ >Evaluation</a>, <a href=../../../../category/ai/ >AI</a></span> </div> </li> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg> <span class=md-ellipsis> 7 min read </span> </div> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <article class="md-content__inner md-typeset"> <a href=https://github.com/rachittshah/rachittshah.github.io/edit/main/docs/blog/posts/2024-03-03-llm-evaluations.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg> </a> <a href=https://github.com/rachittshah/rachittshah.github.io/raw/main/docs/blog/posts/2024-03-03-llm-evaluations.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5"/></svg> </a> <h1 id=introduction-to-llm-evaluations>Introduction to LLM Evaluations<a class=headerlink href=#introduction-to-llm-evaluations title="Permanent link">&para;</a></h1> <p>Large Language Model (LLM) evaluations are the processes and metrics used to measure how well an LLM performs on a given task or meets certain quality criteria. Evaluating an LLM means defining what "good" output looks like—whether that's accuracy, relevance, or safety—and then checking the model's outputs against those expectations. Robust evaluation is critical because it's the only way to know if your model is working as intended and to continuously improve it. In my experience, many AI products that have failed share one common root cause: they never built a reliable evaluation system. Conversely, teams that evaluate early and often can iterate faster and catch problems before users do.</p> <h2 id=the-virtuous-cycle-of-llm-development>The Virtuous Cycle of LLM Development<a class=headerlink href=#the-virtuous-cycle-of-llm-development title="Permanent link">&para;</a></h2> <p>At the heart of LLM development is a virtuous cycle where continuous evaluation and curation enable fast iteration. By testing outputs, identifying weaknesses, and rapidly iterating on improvements, you turn a decent prototype into a trustworthy, high-performing system.</p> <h2 id=why-llm-evaluations-matter>Why LLM Evaluations Matter<a class=headerlink href=#why-llm-evaluations-matter title="Permanent link">&para;</a></h2> <p>LLMs can behave unpredictably or degrade as you tweak prompts or scale usage. Relying on initial "vibe-checks" is often misleading. Systematic evaluations provide ground truth signals about quality and ensure you're not just shipping a cool demo, but a reliable product. Evaluation results not only help in debugging but also guide improvements, much like software tests catch bugs. In short, a solid evaluation process creates a feedback loop: test, identify flaws, fix, and test again.</p> <h2 id=quantitative-vs-qualitative-evaluations>Quantitative vs. Qualitative Evaluations<a class=headerlink href=#quantitative-vs-qualitative-evaluations title="Permanent link">&para;</a></h2> <p>Broadly speaking, there are two main approaches to evaluating LLMs:</p> <ul> <li> <p><strong>Quantitative Evaluations:</strong> These are automated and numeric. For example, for a classification task you might compute accuracy or F1 scores; for translation, metrics like BLEU; and for summarization, metrics like ROUGE. More recently, some teams have started using LLM-based evaluators that assign numeric scores or make pairwise comparisons. Quantitative methods are fast and scalable, but they work best only when the metric truly correlates with real quality.</p> </li> <li> <p><strong>Qualitative Evaluations:</strong> These rely on human judgment. Domain experts or end users assess the outputs for aspects such as correctness, clarity, and overall usefulness. While human evaluations are considered the gold standard for subjective tasks, they are slow, expensive, and do not scale as easily.</p> </li> </ul> <p>In practice, a combination of both methods works best. You might use automated tests to filter out the obvious issues and then apply human review on a smaller subset for a more nuanced assessment.</p> <h2 id=using-llm-evaluations-in-production>Using LLM Evaluations in Production<a class=headerlink href=#using-llm-evaluations-in-production title="Permanent link">&para;</a></h2> <p>Evaluating LLMs isn't a one-time research exercise—it's an ongoing process, especially when models are deployed in production. Setting up an evaluation pipeline early saves you from nasty surprises after deployment. Here's a common layered approach:</p> <h3 id=level-1-unit-tests>Level 1: Unit Tests<a class=headerlink href=#level-1-unit-tests title="Permanent link">&para;</a></h3> <p>Unit tests are assertion-based checks on model outputs, much like traditional software unit tests. You define test inputs and expected outputs or properties, and then automatically verify that the model meets those expectations. For example, if you're building a chatbot, you might assert that when a user asks for pricing info, the response contains a dollar amount. These tests run quickly and cheaply and can catch regressions immediately.</p> <h4 id=pseudo-code-example>Pseudo-code Example:<a class=headerlink href=#pseudo-code-example title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># Pseudo-code: simple unit test for a summarization prompt</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=n>input_text</span> <span class=o>=</span> <span class=s2>&quot;Long article about climate science...&quot;</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=n>summary</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>summarize</span><span class=p>(</span><span class=n>input_text</span><span class=p>)</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=c1># Expect the summary to mention key entities from the article</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=k>assert</span> <span class=s2>&quot;climate&quot;</span> <span class=ow>in</span> <span class=n>summary</span> <span class=ow>and</span> <span class=s2>&quot;carbon&quot;</span> <span class=ow>in</span> <span class=n>summary</span><span class=p>,</span> <span class=s2>&quot;Missing key info in summary&quot;</span>
</span></code></pre></div> <h3 id=level-2-model-driven-and-human-evaluations>Level 2: Model-Driven and Human Evaluations<a class=headerlink href=#level-2-model-driven-and-human-evaluations title="Permanent link">&para;</a></h3> <p>This level involves deeper evaluation, conducted periodically (for example, nightly or with each model update). It may include logging model outputs and having either humans or an LLM-based judge score them. Comparing these scores helps determine the reliability of automated evaluations. While more insightful, these evaluations require additional time and resources.</p> <h3 id=level-3-ab-tests-and-user-metrics>Level 3: A/B Tests and User Metrics<a class=headerlink href=#level-3-ab-tests-and-user-metrics title="Permanent link">&para;</a></h3> <p>Ultimately, the best judge is your end-user. In production, monitoring how model changes impact user behavior and key performance metrics is essential. A/B tests—deploying a new model version to a fraction of users—can reveal differences in engagement, task success, error rates, and overall satisfaction. Although this approach is the gold standard for measuring business impact, it is also the most resource-intensive and requires thorough vetting with Level 1 and Level 2 evaluations beforehand.</p> <h2 id=handling-real-world-constraints>Handling Real-World Constraints<a class=headerlink href=#handling-real-world-constraints title="Permanent link">&para;</a></h2> <p>When deploying LLMs, it's important to balance evaluation rigor with practical constraints:</p> <ul> <li><strong>Latency:</strong> For applications that need real-time responses (such as live chatbots), inline evaluations must be lightweight. Complex checks might be better suited for offline analysis or asynchronous processing.</li> <li><strong>Cost:</strong> Running evaluations, especially with large models, can become expensive. Mitigate this by sampling a subset of traffic for deep evaluation or by caching results.</li> <li><strong>Feedback Loops:</strong> Production systems generate a continuous stream of real user data. Logging inputs, outputs, and user interactions—such as clicks or retries—provides invaluable data that can be fed back into the evaluation pipeline for ongoing improvement.</li> </ul> <h2 id=pitfalls-and-challenges-in-llm-evaluations>Pitfalls and Challenges in LLM Evaluations<a class=headerlink href=#pitfalls-and-challenges-in-llm-evaluations title="Permanent link">&para;</a></h2> <p>Evaluating LLMs is a nuanced art, and there are several common pitfalls to avoid:</p> <h3 id=metric-obsession-without-purpose>Metric Obsession Without Purpose<a class=headerlink href=#metric-obsession-without-purpose title="Permanent link">&para;</a></h3> <p>Collecting a plethora of metrics can result in a data overload that provides little actionable insight. It's important to focus on a few key criteria that directly tie to user needs or system goals. Vague or uncalibrated scores often end up being "nice numbers" that are hard to interpret or act upon.</p> <h3 id=ignoring-domain-expertise>Ignoring Domain Expertise<a class=headerlink href=#ignoring-domain-expertise title="Permanent link">&para;</a></h3> <p>Designing evaluation criteria without input from domain experts can lead to missing what really matters for your specific application. Whether you're dealing with legal documents, medical advice, or any other specialized field, the evaluation should reflect what actual users care about.</p> <h3 id=no-systematic-evaluation>No Systematic Evaluation<a class=headerlink href=#no-systematic-evaluation title="Permanent link">&para;</a></h3> <p>Relying solely on ad-hoc "vibe checks" can leave your system vulnerable to unexpected failures. Establishing a systematic evaluation suite—even if it's just a dozen representative test cases—is essential before shipping a product.</p> <h3 id=overfitting-to-benchmarks>Overfitting to Benchmarks<a class=headerlink href=#overfitting-to-benchmarks title="Permanent link">&para;</a></h3> <p>Focusing too narrowly on a single benchmark can lead to models that excel in that narrow area but fail in real-world applications. The goal should be balanced performance across all relevant aspects rather than chasing a single metric.</p> <h3 id=trusting-automated-judges-blindly>Trusting Automated Judges Blindly<a class=headerlink href=#trusting-automated-judges-blindly title="Permanent link">&para;</a></h3> <p>Automated evaluators, including LLM-based judges, can have their own biases. It's crucial to regularly calibrate these evaluations against human feedback to ensure that the scores reflect true quality.</p> <h3 id=lack-of-statistical-rigor>Lack of Statistical Rigor<a class=headerlink href=#lack-of-statistical-rigor title="Permanent link">&para;</a></h3> <p>LLM outputs can be highly variable. Testing on a small sample may lead to conclusions that are simply the result of chance. Always ensure that your experiments are statistically significant, using larger sample sizes and appropriate statistical tests.</p> <h2 id=rule-based-workflows-for-llm-evaluations>Rule-Based Workflows for LLM Evaluations<a class=headerlink href=#rule-based-workflows-for-llm-evaluations title="Permanent link">&para;</a></h2> <p>One powerful approach to LLM evaluation is the use of rule-based workflows. Instead of relying solely on learned metrics or subjective human judgment, rule-based evaluations use explicit rules or tests to verify that outputs meet specific criteria. For example, if an LLM generates SQL queries, you can actually execute the query to see if it runs without errors. For summarization, you might enforce that all proper nouns from the source appear in the summary.</p> <h3 id=why-rule-based-evaluations>Why Rule-Based Evaluations?<a class=headerlink href=#why-rule-based-evaluations title="Permanent link">&para;</a></h3> <ul> <li><strong>Speed and Determinism:</strong> They're fast, deterministic, and highly interpretable.</li> <li><strong>Cost-Effectiveness:</strong> Simple string or structural checks can run in milliseconds, making them suitable for real-time applications.</li> <li><strong>Clear Guardrails:</strong> They ensure that critical requirements are met, while more nuanced qualities can be assessed with model-based evaluations or human review.</li> </ul> <h2 id=hybrid-evaluation-workflows>Hybrid Evaluation Workflows<a class=headerlink href=#hybrid-evaluation-workflows title="Permanent link">&para;</a></h2> <p>The best evaluation systems combine multiple methods to capture both objective criteria and subjective quality. A typical hybrid workflow might include:</p> <ol> <li><strong>Rule-Based Checks:</strong> Filter out outputs that fail obvious requirements (e.g., format, required keywords, disallowed content).</li> <li><strong>LLM-Based or Automated Scoring:</strong> Assess more subjective qualities such as coherence, relevance, or helpfulness.</li> <li><strong>Human Review:</strong> Provide a final layer of quality control by reviewing a sample of outputs, especially those flagged by automated systems.</li> </ol> <p>For instance, in a chatbot application, rules can enforce politeness and required phrases, an LLM evaluator can score the overall response quality, and human reviewers can examine borderline cases to ensure the system truly aligns with user needs.</p> <h2 id=case-studies-and-industry-learnings>Case Studies and Industry Learnings<a class=headerlink href=#case-studies-and-industry-learnings title="Permanent link">&para;</a></h2> <p>Over the years, I've learned several valuable lessons from both successes and failures in LLM evaluations:</p> <ul> <li><strong>Early and Frequent Evaluation:</strong> Building a domain-specific evaluation system from the start is crucial. A layered approach—with unit tests, periodic deep evaluations, and A/B testing—enables rapid iteration and early detection of issues.</li> <li><strong>Continuous Feedback Loops:</strong> Leveraging real-world data to continuously refine evaluation criteria is essential. A system that constantly logs and learns from each interaction can drive ongoing improvements.</li> <li><strong>Balanced Metrics:</strong> Avoid over-optimizing for a single benchmark. Ensure that improvements in one area do not lead to regressions in others.</li> <li><strong>Calibrated Automation:</strong> Regularly compare automated evaluation results with human judgment. This ensures that your evaluation methods remain aligned with what users actually value.</li> </ul> <h2 id=conclusion>Conclusion<a class=headerlink href=#conclusion title="Permanent link">&para;</a></h2> <p>LLM evaluations are not just an academic exercise—they are a fundamental component of building reliable, user-friendly AI systems. By defining clear success criteria, using a blend of quantitative and qualitative methods, and integrating evaluations into your production workflow, you can catch issues early and continuously improve your models. Though evaluations may not be the most glamorous part of AI development, they are the unsung hero that transforms an impressive demo into a trustworthy, production-ready product.</p> <p>Investing in a robust evaluation system unlocks superpowers for any AI team, enabling rapid fine-tuning, effective debugging, and, ultimately, the delivery of AI products that users can trust. </p> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../../../2024/01/01/evaluation-driven-development/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Evaluation Driven Development"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Evaluation Driven Development </div> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Rachitt Shah </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=/feed_rss_created.xml target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 64c0-17.7 14.3-32 32-32 229.8 0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7 0 64m0 352a64 64 0 1 1 128 0 64 64 0 1 1-128 0m32-256c159.1 0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> <a href=https://twitter.com/rachittshah target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> <a href=https://github.com/rachittshah target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://www.linkedin.com/in/rachittshah target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../../../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../../../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../../../../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>