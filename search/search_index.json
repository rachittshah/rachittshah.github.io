{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What's up?","text":"<p>I'm an independent consultant, staff-level machine learning engineer, and AI systems architect. I write about AI engineering, RAG systems, and how to systematically improve AI applications.</p> <p>After years at top tech companies, I now help organizations build and optimize their AI systems. I focus on:</p> <ul> <li>Designing and implementing RAG systems</li> <li>Optimizing vector search implementations</li> <li>Building scalable AI applications</li> <li>Developing efficient Python applications</li> </ul>"},{"location":"#latest-blog-posts","title":"Latest Blog Posts","text":"<p>[blog_posts]</p>  {% for post in blog_posts %} ### [{{ post.title }}]({{ post.url }}) {{ post.date.strftime('%B %d, %Y') }}  {{ post.description }}  [Read more]({{ post.url }}) \u00bb  --- {% endfor %}"},{"location":"#work-with-me","title":"Work With Me","text":"<p>I help teams adapt to AI's rapid evolution. When I'm not consulting, I produce educational content and courses to help more engineers thrive in the changing AI landscape.</p> <p>Subscribe to my Newsletter</p>"},{"location":"#open-source","title":"Open Source","text":"<p>I maintain several open-source projects and contribute to the AI community:</p> <ul> <li>LangChain RAG Template - Production-ready RAG template</li> <li>Vector Search Benchmarks - Vector DB performance analysis</li> <li>More projects...</li> </ul>"},{"location":"#lets-connect","title":"Let's Connect","text":"<p>Feel free to reach out:</p> <ul> <li> GitHub</li> <li> Twitter</li> <li> LinkedIn</li> <li> Email </li> </ul>"},{"location":"about/","title":"About Me","text":"<p>I'm Rachitt Shah, an AI Engineer and Technical Writer passionate about building and explaining complex systems. I specialize in:</p> <ul> <li>Large Language Models (LLMs)</li> <li>Retrieval Augmented Generation (RAG)</li> <li>Vector Databases</li> <li>Machine Learning Systems</li> </ul>"},{"location":"about/#experience","title":"Experience","text":"<p>I have extensive experience in developing AI-powered applications and systems, with a focus on:</p> <ul> <li>Building production-ready LLM applications</li> <li>Designing and implementing RAG systems</li> <li>Optimizing vector search implementations</li> <li>Writing technical documentation and tutorials</li> </ul>"},{"location":"about/#education","title":"Education","text":"<ul> <li>Bachelor's in Computer Science</li> <li>Various certifications in Machine Learning and AI</li> </ul>"},{"location":"about/#skills","title":"Skills","text":"<ul> <li>Programming Languages: Python, JavaScript, Go</li> <li>Frameworks: PyTorch, TensorFlow, FastAPI</li> <li>Tools: Docker, Kubernetes, Git</li> <li>Cloud Platforms: AWS, GCP, Azure </li> </ul>"},{"location":"contact/","title":"Contact","text":"<p>Get in touch with me for collaborations, consulting, or just to chat about AI and technology.</p>"},{"location":"contact/#connect","title":"Connect","text":"<ul> <li>GitHub: @rachittshah</li> <li>Twitter: @rachittshah</li> <li>LinkedIn: Rachitt Shah</li> <li>Email: contact@rachittshah.com</li> </ul>"},{"location":"contact/#work-with-me","title":"Work With Me","text":""},{"location":"contact/#consulting","title":"Consulting","text":"<p>I offer consulting services in: - RAG system design and implementation - LLM integration and optimization - Vector database selection and setup - AI system architecture</p>"},{"location":"contact/#speaking","title":"Speaking","text":"<p>Available for: - Technical workshops - Conference talks - Webinars - Panel discussions</p>"},{"location":"contact/#writing","title":"Writing","text":"<p>Open to: - Technical blog collaborations - Tutorial series - Documentation projects - Book contributions</p>"},{"location":"contact/#office-hours","title":"Office Hours","text":"<p>I hold regular office hours for the open-source community. Book a slot to discuss: - Technical challenges - Project architecture - Career guidance - Open source contributions</p> <p>Book Office Hours </p>"},{"location":"projects/","title":"Projects","text":"<p>A showcase of my open-source projects and technical contributions.</p>"},{"location":"projects/#rag-projects","title":"RAG Projects","text":""},{"location":"projects/#langchain-rag-template","title":"LangChain RAG Template","text":"<p>A production-ready template for building RAG applications using LangChain. - GitHub Repository - Python, LangChain, FastAPI - Features: Document processing, vector storage, API endpoints</p>"},{"location":"projects/#vector-search-benchmarks","title":"Vector Search Benchmarks","text":"<p>Comprehensive benchmarks of various vector database solutions. - GitHub Repository - Python, Various Vector DBs - Features: Performance metrics, scaling tests, cost analysis</p>"},{"location":"projects/#ai-tools","title":"AI Tools","text":""},{"location":"projects/#prompt-engineering-kit","title":"Prompt Engineering Kit","text":"<p>A toolkit for developing and testing LLM prompts. - GitHub Repository - Python, JavaScript - Features: Prompt templates, testing framework, visualization tools</p>"},{"location":"projects/#model-evaluation-framework","title":"Model Evaluation Framework","text":"<p>Framework for evaluating and comparing LLM performance. - GitHub Repository - Python, PyTorch - Features: Metrics collection, result analysis, reporting</p>"},{"location":"projects/#contributions","title":"Contributions","text":""},{"location":"projects/#open-source","title":"Open Source","text":"<ul> <li>LangChain: Various improvements and bug fixes</li> <li>Weaviate: Documentation and examples</li> <li>FastAPI: Performance optimizations</li> </ul>"},{"location":"projects/#technical-writing","title":"Technical Writing","text":"<ul> <li>AI Engineering Blog Posts</li> <li>RAG System Design Guides</li> <li>Vector Database Tutorials </li> </ul>"},{"location":"ai/","title":"AI Engineering","text":"<p>Welcome to the AI Engineering section! Here you'll find comprehensive guides and tutorials on building AI-powered systems, with a focus on practical implementations and best practices.</p>"},{"location":"ai/#topics-covered","title":"Topics Covered","text":"<ul> <li>Vector Databases - Deep dive into vector storage and similarity search</li> <li>LLM Integration - Guides for integrating language models effectively</li> <li>System architecture and scalability</li> <li>Performance optimization</li> <li>Testing and monitoring</li> </ul>"},{"location":"ai/#getting-started","title":"Getting Started","text":"<p>If you're new to AI Engineering, start with the fundamentals in the Vector Databases section, then explore LLM integration patterns. </p>"},{"location":"ai/llm-integration/","title":"LLM Integration","text":"<p>A comprehensive guide to integrating Large Language Models (LLMs) into applications.</p>"},{"location":"ai/llm-integration/#introduction","title":"Introduction","text":"<p>Effective LLM integration requires careful consideration of architecture, performance, cost, and user experience. This guide covers key patterns and best practices.</p>"},{"location":"ai/llm-integration/#integration-patterns","title":"Integration Patterns","text":""},{"location":"ai/llm-integration/#direct-integration","title":"Direct Integration","text":"<ul> <li>API-based integration</li> <li>Self-hosted models</li> <li>Batch processing</li> <li>Streaming responses</li> </ul>"},{"location":"ai/llm-integration/#rag-integration","title":"RAG Integration","text":"<ul> <li>Document processing</li> <li>Vector storage</li> <li>Query processing</li> <li>Response generation</li> </ul>"},{"location":"ai/llm-integration/#fine-tuning","title":"Fine-tuning","text":"<ul> <li>Dataset preparation</li> <li>Training strategies</li> <li>Model evaluation</li> <li>Deployment considerations</li> </ul>"},{"location":"ai/llm-integration/#best-practices","title":"Best Practices","text":""},{"location":"ai/llm-integration/#prompt-engineering","title":"Prompt Engineering","text":"<ul> <li>Prompt design patterns</li> <li>System messages</li> <li>Few-shot learning</li> <li>Output formatting</li> </ul>"},{"location":"ai/llm-integration/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Caching strategies</li> <li>Batch processing</li> <li>Response streaming</li> <li>Load balancing</li> </ul>"},{"location":"ai/llm-integration/#cost-management","title":"Cost Management","text":"<ul> <li>Token optimization</li> <li>Model selection</li> <li>Caching policies</li> <li>Usage monitoring</li> </ul>"},{"location":"ai/llm-integration/#error-handling","title":"Error Handling","text":"<ul> <li>Rate limiting</li> <li>Fallback strategies</li> <li>Retry mechanisms</li> <li>Monitoring and alerts</li> </ul>"},{"location":"ai/llm-integration/#security-considerations","title":"Security Considerations","text":""},{"location":"ai/llm-integration/#data-privacy","title":"Data Privacy","text":"<ul> <li>Input sanitization</li> <li>Output filtering</li> <li>PII handling</li> <li>Audit logging</li> </ul>"},{"location":"ai/llm-integration/#model-security","title":"Model Security","text":"<ul> <li>Access control</li> <li>API key management</li> <li>Request validation</li> <li>Response filtering</li> </ul>"},{"location":"ai/llm-integration/#monitoring-and-analytics","title":"Monitoring and Analytics","text":""},{"location":"ai/llm-integration/#key-metrics","title":"Key Metrics","text":"<ul> <li>Response times</li> <li>Token usage</li> <li>Error rates</li> <li>Cost per request</li> </ul>"},{"location":"ai/llm-integration/#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Output validation</li> <li>Semantic accuracy</li> <li>Consistency checks</li> <li>User feedback </li> </ul>"},{"location":"ai/vector-databases/","title":"Vector Databases","text":"<p>A comprehensive guide to vector databases and similarity search in AI applications.</p>"},{"location":"ai/vector-databases/#introduction","title":"Introduction","text":"<p>Vector databases are specialized database systems designed to store and efficiently query high-dimensional vectors, which are essential for modern AI applications.</p>"},{"location":"ai/vector-databases/#key-concepts","title":"Key Concepts","text":""},{"location":"ai/vector-databases/#vector-embeddings","title":"Vector Embeddings","text":"<ul> <li>Understanding vector representations</li> <li>Embedding models and techniques</li> <li>Dimensionality considerations</li> <li>Quality and consistency</li> </ul>"},{"location":"ai/vector-databases/#similarity-search","title":"Similarity Search","text":"<ul> <li>Distance metrics</li> <li>Approximate Nearest Neighbors (ANN)</li> <li>Trade-offs in accuracy vs. speed</li> <li>Filtering and hybrid search</li> </ul>"},{"location":"ai/vector-databases/#indexing-methods","title":"Indexing Methods","text":"<ul> <li>HNSW</li> <li>IVF</li> <li>Product Quantization</li> <li>Tree-based methods</li> </ul>"},{"location":"ai/vector-databases/#popular-solutions","title":"Popular Solutions","text":""},{"location":"ai/vector-databases/#open-source","title":"Open Source","text":"<ul> <li>Milvus</li> <li>Weaviate</li> <li>Qdrant</li> <li>FAISS</li> </ul>"},{"location":"ai/vector-databases/#cloud-services","title":"Cloud Services","text":"<ul> <li>Pinecone</li> <li>Weaviate Cloud</li> <li>Azure Vector Search</li> <li>AWS OpenSearch</li> </ul>"},{"location":"ai/vector-databases/#best-practices","title":"Best Practices","text":""},{"location":"ai/vector-databases/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Index tuning</li> <li>Batch processing</li> <li>Caching strategies</li> <li>Hardware considerations</li> </ul>"},{"location":"ai/vector-databases/#scalability","title":"Scalability","text":"<ul> <li>Sharding strategies</li> <li>Replication</li> <li>Load balancing</li> <li>Monitoring and metrics</li> </ul>"},{"location":"ai/vector-databases/#integration-patterns","title":"Integration Patterns","text":"<ul> <li>Bulk operations</li> <li>Real-time updates</li> <li>Error handling</li> <li>Backup and recovery </li> </ul>"},{"location":"blog/","title":"Blog Posts","text":"<p>Welcome to my blog! Here you'll find my thoughts and experiences on AI Engineering, RAG Systems, Venture Capital, and more.</p>"},{"location":"blog/#latest-posts","title":"Latest Posts","text":"<p>[blog_content]</p> <p>The posts are organized by date and tagged for easy navigation. Use the search feature or browse by tags to find specific topics.</p>"},{"location":"blog/#categories","title":"Categories","text":"<ul> <li>AI Engineering &amp; LLMs</li> <li>RAG Systems</li> <li>Venture Capital</li> <li>Technical Notes</li> <li>Career &amp; Personal Growth</li> </ul>"},{"location":"blog/#subscribe","title":"Subscribe","text":"<p>You can subscribe to my blog updates through: - RSS Feed - Twitter - LinkedIn </p>"},{"location":"blog/tags/","title":"Tags","text":"<p>Browse posts by topic:</p> <p>[TAGS] </p>"},{"location":"blog/2022/03/17/blog-post-title-from-file-name/","title":"Blog Post Title From File Name","text":"","tags":["blog","introduction"]},{"location":"blog/2022/03/17/blog-post-title-from-file-name/#hello-world","title":"Hello World","text":"<p>The main motive behind this blog is to share what I write and share who I am, in a minimalist way. Instead of going for a fancy framework, I choose GH pages+Jekyll for ease of maintaning it. </p> <p>Stay connected, stranger. </p>","tags":["blog","introduction"]},{"location":"blog/2022/03/18/venture-capital-memos/","title":"Venture Capital Memos","text":"","tags":["venture-capital","investing","memos"]},{"location":"blog/2022/03/18/venture-capital-memos/#venture-capital-memos","title":"Venture Capital Memos","text":"<p>A very common question asked by aspiring VCs is where do we learn how investments are made? VC is largely a learning on the job role. Feedback cycles take years at the minimum.</p> <p>How do you think like a VC?</p> <p>Enter investment memos: these small documents highlight the usual decision making process of a Venture Capital fund. Many at times, fundraises have memos as well.</p>","tags":["venture-capital","investing","memos"]},{"location":"blog/2022/03/18/venture-capital-memos/#list-of-memos-to-learn","title":"List of memos to learn","text":"<ul> <li>BVP memos</li> <li>Sino Global</li> <li>Memo Collection</li> <li>Angel Investment memos</li> <li>AWS Memo</li> </ul>","tags":["venture-capital","investing","memos"]},{"location":"blog/2022/03/18/venture-capital-memos/#memo-templates","title":"Memo templates","text":"<ul> <li>YC memo template</li> <li>Nextview Ventures</li> <li>Fort Capital</li> <li>Visible VC</li> </ul> <p>Note :I am in no way involved with any of these funds.  If you wish to learn more about VC, drop me a line at LinkedIn</p>","tags":["venture-capital","investing","memos"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/","title":"Venture Capital investments in Open Source","text":"","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#problem","title":"Problem :","text":"<p>Understanding FOSS technologies and investing in open-source tech.</p> <p>Commerical platforms put you at the mercy of closed-source companies. You are subject to\u00a0vendor lock-in\u00a0and\u00a0rent-seeking behavior.</p> <p>No way to combat prices, raise features and get community support.</p>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#solution","title":"Solution","text":"<p>Monetized open-source\u00a0projects give some or all of the code away for free.</p> <p>With the ability to change it.Projects are\u00a0monetized\u00a0via services, premium features, hosting and more. Contributors are users themselves.</p> <p>Freemium plans for user-acquisition, lower CAC, better retention</p>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#key-players","title":"Key Players","text":"<p>Projects</p> <ul> <li>WordPress\u00a0\u2022 The most popular website builder</li> <li>Plausible\u00a0\u2022 Google Analytics alternative</li> <li>Elastic\u00a0\u2022 Search, analyze and visualize data</li> <li>Medusa\u00a0\u2022 Shopify alternative</li> <li>Builder\u00a0\u2022 Visual website builder</li> <li>Posthog\u00a0\u2022 Alternative to Mixpanel and Amplitude</li> <li>Supabase\u00a0\u2022 Firebase alternative</li> <li>Semgrep\u00a0\u2022 Static analysis tool</li> <li>AnonAddy\u00a0\u2022 Anonymous email forwarding</li> <li>Penpot\u00a0\u2022 Figma alternative</li> <li>Canonical \u2022 Linux OS</li> </ul> <p>India:</p> <ul> <li>Appsmith: Raised from Accel India</li> <li>Tooljet: Raised from Nexus Venture Partners</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#predictions","title":"Predictions","text":"<ul> <li>Monetized open source projects will become more\u00a0ambitious.<ul> <li>NocoDB\u00a0and\u00a0Baserow\u00a0are\u00a0Airtable\u00a0alternatives.</li> <li>n8n\u00a0is an alternative to\u00a0Zapier\u00a0and\u00a0Integromat.</li> <li>Medusa\u00a0is a\u00a0Shopify\u00a0alternative.</li> <li>Supabase is a Firebase alternative.</li> <li>Appsmith is a Retool alternative.</li> </ul> </li> <li>Networks will become public goods. Centralized networks have been one of the most effective ways to generate wealth.</li> <li>The Global Open Source Services Market size is expected to reach $60 billion by 2027, rising at a market growth of 17% CAGR during the forecast period. The term 'open source' refers to a kind of licensing agreement, which enables users to independently alter a work, combine work with big projects, use a work in different ways or develop a new workout based on the authentic.</li> <li>The rising number of skilled developers is solving for India for the world. More developers have contributed to Open Source from India than any other country.</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#growth","title":"Growth","text":"<ul> <li>Self-service selling\u00a0dramatically reduces the cost of selling and servicing transactional, lower-revenue deals. The product becomes a vehicle for allowing customers to expand their spending through executing upsells, particularly in usage-based pricing models.\u00a0Chargebee\u00a0offers 2 self-service plans in addition to a free offering, which enables SMB and mid-market customers to grow with the platform without needing to talk to sales.</li> <li>Data-driven targeting\u00a0uses product data in sales targeting and upsells motion; for instance, providing your sales team with a list of customers who are above their usage limits and ready to pay.\u00a0Nearpod\u00a0collects data around which teachers are actively using its platform and then leverages this to encourage school districts to become customers.</li> <li>New or premium feature adoption\u00a0can be improved by guiding users to that feature with product popups and callouts based on their usage patterns and use-case.\u00a0MURAL\u00a0surfaces new features in-app with contextual triggers, while also providing an in-depth changelog to demonstrate all of the value they are continuously adding to their product.</li> <li>Community development\u00a0involves fostering a community of users who can help each other understand the product and develop new innovations in usage. This community will form a key source of product advocacy and evangelism, with paying customers advocating to free users, and free users evangelizing the product to prospective users.\u00a0You should support and foster the community by providing forums and events (user conferences and smaller gatherings) where they can interact, uplifting the most active users of the community, and ensuring company employees interact and become members of the community themselves.\u00a0Postman\u00a0has fostered an active community of developers using the product and continues to invest in it.</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#opportunities","title":"Opportunities","text":"<ul> <li>The counter position\u00a0to\u00a0compete\u00a0with incumbents. Make it hard for them to mimic your strategy. Copying should lead to cannibalizing their existing business.\u00a0Medusa\u00a0is a\u00a0Shopify\u00a0alternative. It's unlikely that Shopify will open source. Even if Medusa becomes a formidable competitor.</li> <li>Permissionless contribute\u00a0to open-source projects. Use open-source contributions to build a portfolio and find jobs. Laszlo Block, former VP of People Operations at Google,\u00a0says\u00a0the number of Google employees without a college education is rising.</li> <li>Open-source alternatives avoid\u00a0platform risk,\u00a0vendor lock-in\u00a0and\u00a0rent-seeking behavior. Use code that you can\u00a0fork and self-host. Platforms\u00a0can raise prices without providing more value because switching costs are high.</li> <li>Turn complaints into\u00a0contributions. Accept\u00a0pull requests. Along with feature requests. Augment your dev team with open-source contributions.</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#security","title":"Security","text":"<ul> <li>securing serverless in the public cloud, perhaps by isolating serverless workloads in the public cloud with granular account-level segmentation, and limiting exposure through the use of blast-radius architecture</li> <li>rethinking authentication for transient serverless workloads by using ephemeral credentials and short-lived tokens, which are key risk mitigators for credential exposure</li> <li>protecting your availability in a serverless landscape with robust perimeter security that deploys public and internal functions at discrete gateways</li> <li>upgrading risk assessment, governance, and awareness by, for example, adopting policy as code for the codification of organizational policies; using regulatory frameworks in automated governance pipelines for cloud-service provisioning; and deploying all serverless workloads using an embedded\u00a0DevSecOps\u00a0pipeline</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#risks","title":"Risks","text":"<ul> <li>Consulting: Services\u00a0are less scalable than hosting and dual-license models. Consider marginal costs before you choose this strategy.</li> <li>Community Backlash\u00a0\u2022 Moving free features to paid tiers may lead to a backlash.</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#key-lessons","title":"Key Lessons","text":"<ul> <li>Users\u00a0are the real winners of monetized open source. Public goods have less lock-in.</li> <li>Value creation\u00a0does not automatically lead to value capture. Two-way rating systems, proof of stake protocols, and airdrops are uncornered innovations.</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#issues","title":"Issues","text":"<ul> <li>IP\u00a0rights will be hard to enforce in the new world.\u00a0CryptoPunks creators\u00a0are under fire for an inconsistent approach to derivatives.\u00a0Bored Apes\u00a0are slightly more lenient.\u00a0NFTs\u00a0gave us digital scarcity.\u00a0Legitimacy\u00a0and social consensus will rule the day.</li> <li>Wealthy\u00a0benefactors\u00a0will use open-source projects to prop up closed ecosystems and attract talent. See\u00a0Apple with Swift\u00a0and\u00a0Meta with React.</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/18/venture-capital-in-open-source/#links","title":"Links","text":"<ul> <li>https://www.insightpartners.com/blog/product-led-growth-the-new-paradigm-in-software-selling/#:~:text=Open source is offering source,a freemium or free trial.</li> <li>https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/saas-open-source-and-serverless-a-winning-combination-to-build-and-scale-new-businesses</li> <li>https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/saas-open-source-and-serverless-a-winning-combination-to-build-and-scale-new-businesses</li> <li>https://msupernaut.com/2021/11/12/open-source-%f0%9f%92%9c-venture-capital/</li> </ul>","tags":["venture-capital","open-source","investing"]},{"location":"blog/2022/03/19/how-to-cold-email/","title":"How to Cold Email","text":"","tags":["career","networking","communication"]},{"location":"blog/2022/03/19/how-to-cold-email/#how-to-write-a-good-cold-email","title":"How to write a good cold email?","text":"<p>If you're looking for job,internship, customers or fundraising, a cold email is your best shoot at reaching out(unless you know people from the organization).</p> <p>The beauty of cold emailing is that it's a direct and upfront ask, you know what you want, if you don't define and send that email.</p> <ul> <li>One line about who you are, and what do you do.</li> <li>Hello {receiver}, I'm {name}, studying/working with {name} and I wish to {request}</li> <li>Sharing about yourself</li> <li>Adding 2 to 5 lines about the key highlights which make you a good fit for the request you've asked.</li> <li>Be direct, short and crisp. Writing essays isn't saving anyone's time. Be concise and respectful.</li> <li>Quantify and share your proof of work. If you worked on a feature, show the time it saved or costs reduced. If you gained 100 customers, add that. Show numbers so people understand you better.</li> <li>Add all relevant links in the email. The reader isn't gonna spend his time looking you up. Respect their time.</li> <li>One line about who you are, and what do you do.</li> <li>Close the email wiht a call to action. Add a personal touch, get as personalized as possible!</li> </ul> <p>Sounds interesting? Write a cold email and get what you want! Drop me text at LinkedIn if it helps.</p>","tags":["career","networking","communication"]},{"location":"blog/2022/06/28/vc-modelling/","title":"VC Modelling","text":"","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#venture-capital-financial-modelling-notebook","title":"Venture Capital financial modelling notebook","text":"<p>I've always wanted to cover how captables are modelled. Using this github repo, I show how can we build captables, calculate expenses and EBIT, and company valuations.</p> <p>Link to github repo.</p>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#free-cash-flow","title":"Free Cash Flow:","text":"<p>Free cash flow (FCF) represents the cash a company generates after accounting for cash outflows to support operations and maintain its capital assets.</p> <p>There are two main approaches to calculating FCF. The first approach uses cash flow from operating activities as the starting point, and then makes adjustments for interest expense, the tax shield on interest expense, and any capital expenditures (CapEx) undertaken that year. </p> <p>The second approach uses earnings before interest and taxes (EBIT) as the starting point, then adjusts for income taxes, non-cash expenses such as depreciation and amortization, changes in working capital, and CapEx. In both cases, the resulting numbers should be identical, but one approach may be preferred over the other depending on what financial information is available.</p>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#ebit","title":"EBIT","text":"<p>Earnings before interest and taxes (EBIT) is an indicator of a company's profitability. EBIT can be calculated as revenue minus expenses excluding tax and interest. EBIT is also referred to as operating earnings, operating profit, and profit before interest and taxes.</p>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#valuation","title":"Valuation","text":"<p>A business valuation is the process of determining the economic value of a business, giving owners an objective estimate of the value of their company. Typically, a business valuation happens when an owner is looking to sell all or a part of their business, or merge with another company.</p>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#prepost-valuations","title":"Pre/Post Valuations","text":"<p>Pre-money and post-money differ in the timing of valuation. Pre-money valuation refers to the value of a company not including external funding or the latest round of funding. Post-money valuation includes outside financing or the latest capital injection.</p>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#captable","title":"Captable","text":"<p>A capitalization table is a table providing an analysis of a company's percentages of ownership, equity dilution, and value of equity in each round of investment by founders, investors, and other owners.</p>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2022/06/28/vc-modelling/#todo","title":"Todo","text":"<ul> <li> Add how to model captables</li> <li> How EBIT is measured</li> <li> Formulas for measurements</li> <li> Add info about termsheets</li> </ul>","tags":["venture-capital","finance","modeling"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/","title":"LLMOps 101","text":"<p>When we integrate LLMs into our applications, there's a major boost in the features of your apps. However, as with any complex system, it is crucial to have mechanisms in place that allow us to monitor and evaluate their performance over time. </p> <p>Logging is a fundamental aspect of this oversight. This blog post will explore why logging is essential for those utilizing LLMs any products, and how to follow an evaluation framework and production monitoring approach.</p> <p>Building apps with LLMs has the same principles as software engineering, with a focus on building reliable and scalable apps. </p>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/#understanding-llm-behavior","title":"Understanding LLM Behavior","text":"<p>LLMs are inherently non-deterministic; the same input can lead to different outputs depending on various factors, including the model's training and the context provided. Logging helps us to record each interaction with the LLM, enabling us to understand its behavior by analyzing its responses over time. This is the foundation of building a reliable AI-powered application.</p> <p>Some key KPIs to observe:</p> <ul> <li>Cost Analysis: By tracking the cost of requests in real time, developers can manage budgets effectively and forecast expenses with greater accuracy.</li> <li>Token Metrics: Understanding token usage helps optimize prompt design, potentially lowering costs and improving response quality.</li> <li>Latency Averages: Performance is key in user experience. Mean latency metrics are crucial for identifying lags and making necessary optimizations.</li> <li>Success and Failure Rates: Real-time assessment of request outcomes enables developers to swiftly address failures and enhance success rates.</li> <li>User Engagement: Identifying your user base and their usage patterns allows for better targeting and personalization strategies.</li> <li>Model Popularity: Knowing which models are most used can guide decisions about future integrations or depreciations.</li> </ul>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/#identifying-and-resolving-errors","title":"Identifying and Resolving Errors","text":"<p>Even the most advanced LLMs can produce errors, including misunderstandings, non sequiturs, and \"hallucinations,\" where the model confidently presents incorrect information. Logging is essential for identifying when and why these errors occur. By analyzing the logs, we can tweak our prompts or the model's parameters to reduce the incidence of such errors and improve the overall accuracy of the system.</p> <ul> <li>Error Rate Diagnosis: A high-level view of errors can pinpoint systemic issues that need immediate attention.</li> <li>Error Type Distribution: Classifying errors helps in understanding what kind of issues are most prevalent and how to prioritize fixes.</li> <li>Error Trend Analysis: Observing the trends of errors over time can indicate the robustness of newly released features or models.</li> <li>Rescue Success: Automatic retries and fallbacks are a safety net; monitoring their success helps ensure reliability even in failure scenarios.</li> </ul>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/#measuring-performance-and-reliability","title":"Measuring Performance and Reliability","text":"<p>In order to ensure that an LLM is performing optimally and reliably within an application, it's vital to track specific KPIs that can provide actionable insights into its behavior. These KPIs help in understanding how the LLM interacts with users and handles various queries, thus informing decisions on system improvements and optimizations.</p> <p>Some key KPIs for measuring performance and reliability include:</p> <ul> <li>Response Time: The average time taken for the LLM to respond to a query. This KPI is crucial for user satisfaction as it directly impacts the user experience.</li> <li>Uptime / Availability: The percentage of time the LLM is operational and available for use without any outages, indicating system reliability.</li> <li>Error Rate: The ratio of the number of failed requests to the total number of requests, which helps in pinpointing stability issues.</li> <li>Success Rate: The percentage of queries handled successfully without any errors or interventions, showcasing the efficacy of the LLM.</li> <li>Recovery Time: The average time it takes for the LLM to recover from an error or failure, reflecting the resilience of the system.</li> <li>Quality of Responses: Measure the accuracy and relevance of the LLM's responses through qualitative analysis or user ratings.</li> <li>Throughput: The number of requests processed by the LLM in a given time frame, indicating the system's capacity to handle load.</li> <li>Fallback Rate: The frequency with which the system needs to resort to fallback mechanisms due to LLM's inability to provide an appropriate response.</li> <li>Repeat Interaction Rate: The rate at which users need to ask follow-up questions to get satisfactory answers, shedding light on the clarity and completeness of the LLM's responses.</li> <li>Benchmark Against Goals: How the LLM's performance aligns with predefined benchmarks or objectives for various metrics, reflecting whether the system meets the set performance goals.</li> </ul>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/#feedback-loops-for-machine-learning","title":"Feedback Loops for Machine Learning","text":"<p>For LLMs to improve, they need high-quality, structured data to learn from. Logging provides invaluable data about the model's inputs and outputs, which can be used for further training and refinement. This creates a feedback loop where the performance of the LLM is continuously improved based on actual usage data.</p> <ul> <li>Feedback Volume: Keeping a pulse on how much feedback you're receiving is essential for understanding user engagement.</li> <li>Feedback Quality: Inspecting the scores and sentiments in feedback helps gauge user happiness and areas needing improvement.</li> <li>Trend Analysis: A trend line of feedback over time allows developers to measure the impact of changes and maintain a trajectory of improvement.</li> <li>Engaged User Base: Knowing who is providing feedback can help develop a community of testers and brand advocates.</li> </ul>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/#enhancing-user-experience","title":"Enhancing User Experience","text":"<p>User feedback is a vital aspect of improving AI applications. By combining user feedback with detailed logs of LLM interactions, we can understand how users perceive the LLM's responses and identify areas where the user experience can be enhanced.</p> <ul> <li>Unique Users: Quantifying individual users helps in understanding the reach of your app and catering to diverse needs.</li> <li>Top Users: Identifying power users can help in community building and finding champions for your product.</li> <li>Usage Frequency: Tracking how often users engage with your app sheds light on its stickiness and daily relevance.</li> <li>Feedback Interaction: User feedback serves as a direct line to customer satisfaction and is critical for iterative development.</li> </ul>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2023/12/17/llmops-101-logging-and-monitoring-llms/#business-and-operational-insights","title":"Business and Operational Insights","text":"<p>Logs can reveal trends in how users interact with the application, providing business insights such as the peak times for LLM usage, the most common types of queries, or areas where users frequently encounter difficulties. This information is essential for operational planning and for developing strategies to encourage more effective use of the AI system.</p> <ul> <li>Unique Users: Quantifying individual users helps in understanding the reach of your app and catering to diverse needs.</li> <li>Top Users: Identifying power users can help in community building and finding champions for your product.</li> <li>Usage Frequency: Tracking how often users engage with your app sheds light on its stickiness and daily relevance.</li> <li>Feedback Interaction: User feedback serves as a direct line to customer satisfaction and is critical for iterative development.</li> </ul>","tags":["llm","mlops","monitoring","production"]},{"location":"blog/2024/01/01/evaluation-driven-development/","title":"Evaluation Driven Development","text":"<p>As a software engineer, I've been a huge fun of using test driven development(TDD), but how do we test something like LLMs? LLMs are far away from classical ML models, a stark difference is traditional ML models are often good at doing one task, but LLMs can do a variety of them.</p> <p>Thinking about it as a engineer, it used to scare me when each API returns a new response, not a very reliable system, is it?</p> <p>That's why I believe everyone building with LLMs needs to adopt the practice of using evals while building your LLM powered applications. </p> <p>For any software application, backward compatibility is a vital aspect to consider. It ensures that newer versions of the software will work with older ones, maintaining functionality and preventing inconveniences that can arise when making upgrades. When it comes to LLMs, however, ensuring backward compatibility can be a substantial challenge.</p> <p>LLM software, by its very nature, is continually evolving, with newer and more advanced models being released regularly. While one might assume that these software improvements would have linear upward trajectory in terms of performance and usability, the truth is, it may not be the same for certain specific use cases. Upgrading from an earlier model to a newer one might cause discrepancies in results since each model has its unique characteristics and behaviours.</p> <p>Ensuring backward compatibility, while challenging, is not an impossible task. Below are some strategies that can help in achieving this:</p> <ul> <li>Prompts Standardization: Developing a standardized syntax or nomenclature for prompts can go a long way in ensuring backward compatibility. This would imply a set of universally recognized and accepted guidelines for writing prompts that apply to all existing models and also newer ones.</li> <li>Thorough Testing: A robust testing process can help mitigate compatibility issues. Older prompts should be rigorously tested with newer models. Any prompt that does not achieve the desired or expected result should be adjusted or rewritten.</li> <li>Establish Clear Documentation: Detailed documentation of all prompts is crucial. When a developer understands the original intentions and structures behind a prompt, they will be better equipped to make necessary adjustments with newer models.</li> <li>Creating Model-Specific Code Paths: For critical applications where backward compatibility must be maintained, developers could consider running two versions of the model (the older and the newer one) and switch between them based on the situation. The decision on which model to use could depend on the prompts or the quality of responses.</li> </ul>","tags":["llm","development","evaluation","best-practices"]},{"location":"blog/2024/01/01/evaluation-driven-development/#how-do-you-actually-use-evals","title":"How do you actually use evals?","text":"<p>Using evals largely differs on what you're building. </p> <p>The best starting point to take while building is think evals first, how will the user prompt the LLM and what are the odds of the LLM returning the correct text? </p> <p>There is also the issue of 'prompt compatibility'. A prompt that worked perfectly with an older model may not necessarily evoke the intended response from a newer one, compelling developers to re-engineer their prompts, which can be quite a time-consuming task.</p> <p>IMO, starting from evals and going into the application behaviour is a great way to replicate TDD while building applications! Some things to consider:</p> <ul> <li>User behaviour</li> <li>Type of application</li> <li>Complexity: are you building agents or chains?</li> <li>Tools provided to the base LLM</li> <li>Prompt engineering: setting roles is a good hack and will ensure better evals!</li> </ul>","tags":["llm","development","evaluation","best-practices"]},{"location":"blog/2024/01/01/evaluation-driven-development/#metrics-that-matter","title":"Metrics that matter","text":"<p>In GenAI, user stickiness seems to be the largest issue, if you're a devtool or a consumer app, retention is a pain. Evals can in part help eliminate this by ensuring completion quality. </p> <p>Some key KPIs:</p> <ul> <li>faithfulness - the factual consistency of the answer to the context base on the question.</li> <li>context_precision - a measure of how relevant the retrieved context is to the question. Conveys quality of the retrieval pipeline.</li> <li>answer_relevancy - a measure of how relevant the answer is to the question</li> <li>context_recall: measures the ability of the retriever to retrieve all the necessary information needed to answer the question.</li> <li>Harmfulness: reducing harmful outputs.</li> <li>PII: making sure senstive user data is not leaked by mistake.</li> </ul>","tags":["llm","development","evaluation","best-practices"]},{"location":"blog/2024/01/01/evaluation-driven-development/#how-does-this-affect-your-product-kpis","title":"How does this affect your product KPIs?","text":"<p>Evals will make sure your NPS from users increases, while making the need to log each interaction less important, since there's an established metric for output quality.</p> <p>Think of using evals as having a QA engineer in form of an SDK!</p>","tags":["llm","development","evaluation","best-practices"]},{"location":"rag/","title":"RAG Systems","text":"<p>Retrieval Augmented Generation (RAG) is a powerful approach that combines the capabilities of large language models with external knowledge retrieval. This section covers best practices, case studies, and implementation details for building effective RAG systems.</p>"},{"location":"rag/#topics-covered","title":"Topics Covered","text":"<ul> <li>Best Practices - Guidelines and recommendations for building robust RAG systems</li> <li>Case Studies - Real-world examples and implementations</li> <li>Technical deep dives into specific RAG components</li> </ul>"},{"location":"rag/#getting-started","title":"Getting Started","text":"<p>If you're new to RAG, start with the Best Practices guide to understand the fundamental concepts and common pitfalls to avoid. </p>"},{"location":"rag/best-practices/","title":"RAG Best Practices","text":"<p>This guide covers essential best practices for building effective RAG systems.</p>"},{"location":"rag/best-practices/#1-document-processing","title":"1. Document Processing","text":"<ul> <li>Clean and preprocess documents thoroughly</li> <li>Implement effective chunking strategies</li> <li>Maintain document metadata</li> <li>Handle different document formats consistently</li> </ul>"},{"location":"rag/best-practices/#2-vector-storage","title":"2. Vector Storage","text":"<ul> <li>Choose appropriate embedding models</li> <li>Optimize vector dimensions</li> <li>Implement efficient indexing</li> <li>Consider hybrid search approaches</li> </ul>"},{"location":"rag/best-practices/#3-retrieval-strategy","title":"3. Retrieval Strategy","text":"<ul> <li>Design effective query processing</li> <li>Implement re-ranking mechanisms</li> <li>Use semantic and keyword search</li> <li>Handle edge cases and failures</li> </ul>"},{"location":"rag/best-practices/#4-response-generation","title":"4. Response Generation","text":"<ul> <li>Implement proper prompt engineering</li> <li>Handle context limitations</li> <li>Ensure source attribution</li> <li>Validate generated responses</li> </ul>"},{"location":"rag/best-practices/#5-system-monitoring","title":"5. System Monitoring","text":"<ul> <li>Track retrieval quality metrics</li> <li>Monitor embedding consistency</li> <li>Implement feedback loops</li> <li>Log system performance </li> </ul>"},{"location":"rag/case-studies/","title":"RAG Case Studies","text":"<p>Real-world examples of RAG system implementations and their outcomes.</p>"},{"location":"rag/case-studies/#enterprise-knowledge-base","title":"Enterprise Knowledge Base","text":""},{"location":"rag/case-studies/#challenge","title":"Challenge","text":"<ul> <li>Large volume of internal documentation</li> <li>Multiple document formats</li> <li>Need for real-time access</li> <li>Security requirements</li> </ul>"},{"location":"rag/case-studies/#solution","title":"Solution","text":"<ul> <li>Implemented hybrid chunking strategy</li> <li>Used domain-specific embeddings</li> <li>Built custom reranking pipeline</li> <li>Integrated with SSO</li> </ul>"},{"location":"rag/case-studies/#results","title":"Results","text":"<ul> <li>80% reduction in search time</li> <li>90% accuracy in retrievals</li> <li>Improved employee productivity</li> </ul>"},{"location":"rag/case-studies/#customer-support-system","title":"Customer Support System","text":""},{"location":"rag/case-studies/#challenge_1","title":"Challenge","text":"<ul> <li>High volume of support tickets</li> <li>Need for consistent responses</li> <li>Multiple product lines</li> <li>Multiple languages</li> </ul>"},{"location":"rag/case-studies/#solution_1","title":"Solution","text":"<ul> <li>Implemented multilingual embeddings</li> <li>Built product-specific indexes</li> <li>Created response templates</li> <li>Integrated feedback loop</li> </ul>"},{"location":"rag/case-studies/#results_1","title":"Results","text":"<ul> <li>60% faster response time</li> <li>40% reduction in escalations</li> <li>Improved customer satisfaction</li> </ul>"},{"location":"rag/case-studies/#technical-documentation","title":"Technical Documentation","text":""},{"location":"rag/case-studies/#challenge_2","title":"Challenge","text":"<ul> <li>Complex technical content</li> <li>Frequent updates</li> <li>Version control requirements</li> <li>Code snippets and diagrams</li> </ul>"},{"location":"rag/case-studies/#solution_2","title":"Solution","text":"<ul> <li>Implemented version-aware indexing</li> <li>Built code-specific chunking</li> <li>Created diagram extraction pipeline</li> <li>Integrated with Git workflow</li> </ul>"},{"location":"rag/case-studies/#results_2","title":"Results","text":"<ul> <li>70% faster documentation searches</li> <li>85% accuracy in code snippet retrieval</li> <li>Improved developer experience </li> </ul>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""}]}